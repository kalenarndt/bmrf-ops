---
# yaml-language-server: $schema=https://raw.githubusercontent.com/budimanjojo/talhelper/master/pkg/config/schemas/talconfig.json
clusterName: &clusterName expanse
endpoint: https://${clusterEndpointIP}:6443

# renovate: depName=ghcr.io/siderolabs/installer datasource=docker
talosVersion: v1.9.2
# renovate: depName=ghcr.io/siderolabs/kubelet datasource=docker
kubernetesVersion: 1.32.1

allowSchedulingOnMasters: true
cniConfig:
  name: none

additionalApiServerCertSans: &san
  - ${clusterName}.${clusterDomain}
  - ${clusterEndpointIP}
  - 127.0.0.1 # KubePrism https://www.talos.dev/v1.6/kubernetes-guides/configuration/kubeprism/
additionalMachineCertSans: *san

nodes:
  - hostname: eros.${clusterDomain}
    ipAddress: 172.16.11.13
    installDiskSelector:
      name: /dev/nvme0n1
    controlPlane: true
    machineDisks:
      - device: /dev/nvme1n1
        partitions:
          - mountpoint: /var/mnt/data
    networkInterfaces:
      - deviceSelector:
          hardwareAddr: 58:47:ca:7a:8b:2a
          driver: i40e
        mtu: ${mtu}
        addresses:
          - 172.16.11.21/24
        routes:
          - network: 0.0.0.0/0
            gateway: ${defaultGW}
        vip:
          ip: ${clusterEndpointIP}
      - deviceSelector:
          driver: igc
        ignore: true
    patches:
      - &kubelet_extra_mounts |-
        machine:
          kubelet:
            extraMounts:
              - destination: /var/mnt/data
                type: bind
                source: /var/mnt/data
                options:
                  - rbind
                  - rshared
                  - rw

controlPlane:

  schematic:
    customization:
      extraKernelArgs:
        - apparmor=0           # Less security, more speed
        - init_on_alloc=0      # Less security, more speed
        - init_on_free=0       # Less security, more speed
        - intel_iommu=on       # PCI Passthrough
        - iommu=pt             # PCI Passthrough
        - mitigations=off      # Less security, more speed
        - security=none        # Less security, more speed
        - net.ifnames=1        # Enable predictable NIC naming

      systemExtensions:
        officialExtensions:
          - siderolabs/i915-ucode
          - siderolabs/intel-ucode
          - siderolabs/mei
          - siderolabs/thunderbolt
          - siderolabs/iscsi-tools
          - siderolabs/util-linux-tools

  patches:
    # Cluster configuration
    - |-
      cluster:
        allowSchedulingOnMasters: true
        proxy:
          disabled: true

    # Disable coreDNS because we are deploying with helmfile and managing with flux
    - |-
      cluster:
        coreDNS:
          disabled: true

    # ETCD configuration
    - |-
      cluster:
        etcd:
          advertisedSubnets:
            - 172.16.11.0/24

    # Disable default API server admission plugins.
    - |-
      - op: remove
        path: /cluster/apiServer/admissionControl

    # Force nameserver
    - |-
      machine:
        network:
          nameservers:
            - ${dnsIP}

    # Configure NTP
    - |-
      machine:
        time:
          disabled: false
          servers:
            - time.google.com

    # Disable search domain everywhere
    - |-
      machine:
        network:
          disableSearchDomain: true

    # Configure cluster loopback
    - |-
      machine:
        network:
          extraHostEntries:
            - ip: ${clusterEndpointIP}
              aliases:
                - ${clusterName}.${clusterDomain}
            - ip: ${storageIP}
              aliases:
                - storage.${clusterDomain}

    # Enable KubePrism
    - |-
      machine:
        features:
          kubePrism:
            enabled: true
            port: 7445

    # Kubelet configuration
    - |-
      machine:
        kubelet:
          extraArgs:
            rotate-server-certificates: "true"
          nodeIP:
            validSubnets:
            - 172.16.11.0/24

    # Configure containerd
    - |-
      machine:
        files:
          - op: create
            path: /etc/cri/conf.d/20-customization.part
            content: |
              [plugins]
                [plugins."io.containerd.grpc.v1.cri"]
                  enable_unprivileged_ports = true
                  enable_unprivileged_icmp = true
                [plugins."io.containerd.grpc.v1.cri".containerd]
                  discard_unpacked_layers = false
                [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
                  discard_unpacked_layers = false

    # Enable K8s Talos API Access
    - |-
      machine:
        features:
          kubernetesTalosAPIAccess:
            enabled: true
            allowedRoles:
              - os:admin
            allowedKubernetesNamespaces:
              - system-controllers

    # Configure nfs mount options
    - |-
      machine:
        files:
          - op: overwrite
            path: /etc/nfsmount.conf
            permissions: 0o644
            content: |
              [ NFSMount_Global_Options ]
              nfsvers=4.2
              hard=True
              nconnect=16
              noatime=True
    # Custom sysctls
    - |-
      machine:
        sysctls:
          fs.inotify.max_user_watches: 1048576   # Watchdog
          fs.inotify.max_user_instances: 8192    # Watchdog
          net.core.default_qdisc: fq             # 10Gb/s
          net.core.rmem_max: 67108864            # 10Gb/s | Cloudflared / QUIC
          net.core.wmem_max: 67108864            # 10Gb/s | Cloudflared / QUIC
          net.ipv4.tcp_mtu_probing: 1            # 10Gb/s | Jumbo frames
          net.ipv4.tcp_rmem: 4096 87380 33554432 # 10Gb/s
          net.ipv4.tcp_wmem: 4096 65536 33554432 # 10Gb/s
          net.ipv4.tcp_window_scaling: 1         # 10Gb/s
          net.ipv4.tcp_fastopen: 3               # Send and accept data in the opening SYN packet
          vm.nr_hugepages: 1024                  # PostgresSQL

    # Custom sysfs settings
    - |-
      machine:
        sysfs:
          devices.system.cpu.intel_pstate.hwp_dynamic_boost: 1
          devices.system.cpu.cpu0.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu1.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu2.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu3.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu4.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu5.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu6.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu7.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu8.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu9.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu10.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu11.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu12.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu13.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu14.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu15.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu16.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu17.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu18.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu19.cpufreq.energy_performance_preference: balance_performance

    # Configure udev rules
    - |-
      machine:
        udev:
          rules:
            # Thunderbolt
            - ACTION=="add", SUBSYSTEM=="thunderbolt", ATTR{authorized}=="0", ATTR{authorized}="1"
            # Intel GPU
            - SUBSYSTEM=="drm", KERNEL=="renderD*", GROUP="44", MODE="0660"

    # v2 Longhorn rules
    - |-
      machine:
        kernel:
          modules:
            - name: nvme_tcp
            - name: vfio_pci